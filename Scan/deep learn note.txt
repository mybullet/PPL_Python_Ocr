人工智能是一个大领域，机器学习只是人工智能领域中一部分；
 
机器学习的一般流程为：
收集并标注数据，训练一个分类器，模型评估。
一些简单的机器学习算法，例如线性回归或决策树，可以清晰地了解其工作原理和模型的决策过程。
深度学习是一种基于神经网络算法的机器学习方法，是一个黑盒子，无法直接观察到模型的内部工作方式。
机器学习的参数成千上百万个，需要很强的算力，所以移动端很吃力。
深度学习包括DNN,CNN,RNN等神经网络结构和算法。

K近邻（KNN）是一种传统的分类算法，一般步骤为：
计算数据集中的点与目标点之间的距离，然后按由近到远排序；
取一个K值，即从序列中取前K个数据，计算这K个数据中各个类别出现的概率；
最大概率者即为目标点的类别。
无需训练分类器，所以训练复杂度为0；
计算复杂度为n，即数据集的大小。

若用KNN进行图像识别，其距离计算方法为：对应像素点做差然后求和，即为目标图片与某一数据图片的像素距离；
使用KNN算法做图像识别时，关注的是背景，而图像识别需要关注的是主体，所以KNN不适合做图像识别。

深度神经网络（DNN）基本工作流程：
1）先对原始数据做数据预处理，比如图片预处理、字符串转数字；
2）定义好隐层数和每层的神经元个数，然后通过基于正态分布的随机法对权重参数进行初始化(W)；
3）对输入数据逐层计算其得分函数值和基于非线性化的激活函数值(relu,sigmoid)，上一层的激活函数值作为下一个隐层的输入，最后通过输出层计算一个预测值；
4）最后一个隐层到输出层之间，一般不再做激活函数处理，因为最后算出来的预测结果值会很小，不利于反向传播。
5）基于分类类别计算其损失函数值Loss，为避免参数过大过小，还需要在损失值的基础上计算其正则惩罚项(R(W))；
6）上述即为正向传播；
7）基于链式法则和梯度下降法(求偏导)，反向逐层更新权重参数值和偏置值(-学习率*偏导数)，使得损失值达到最小，此为反向传播；
8）为降低训练计算量和过拟合风险，可以采用drop-out方法，即在每次迭代训练的时候，随机关闭一些神经元节点；
9）最终训练的模型应能满足测试集，而非训练集，所以需要避免模型在训练集身上出现过拟合的现象，模型不能太强，需要呈现一定的通用性；
